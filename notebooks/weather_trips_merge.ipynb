{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/external/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveDwdData(url, path, f_name):\n",
    "    \n",
    "    print('Download ' + f_name + ' from ' + url + ' and save to ' + path)\n",
    "    \n",
    "    file = requests.get(url)\n",
    "    open(path + f_name, 'wb').write(file.content)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDwdData(url, path, f_name):\n",
    "    \n",
    "    saveDwdData(url, path, f_name)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    df = pd.read_csv(path + f_name, sep=';')\n",
    "    print('Created data frame of ' + f_name)\n",
    "    \n",
    "    os.remove(path + f_name)\n",
    "    print('Zip file removed: ' + path + f_name)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filterForYear(df, year):\n",
    "    \n",
    "    df.rename(columns={\"MESS_DATUM\": \"timestamp\"}, inplace=True)\n",
    "    \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'].astype(str))\n",
    "    \n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    df = df[df.index.year == year]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepWeather():\n",
    "    urls = {\n",
    "        'air_temp':'https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/10_minutes/air_temperature/historical/10minutenwerte_TU_00691_20100101_20191231_hist.zip',\n",
    "        'air_temp_extr':'https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/10_minutes/extreme_temperature/historical/10minutenwerte_extrema_temp_00691_20100101_20191231_hist.zip',\n",
    "        'wind':'https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/10_minutes/wind/historical/10minutenwerte_wind_00691_20100101_20191231_hist.zip',\n",
    "        'wind_extr':'https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/10_minutes/extreme_wind/historical/10minutenwerte_extrema_wind_00691_20100101_20191231_hist.zip',\n",
    "        'precipitation':'https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/10_minutes/precipitation/historical/10minutenwerte_nieder_00691_20100101_20191231_hist.zip',\n",
    "        'solar':'https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/10_minutes/solar/historical/10minutenwerte_SOLAR_00691_20100101_20191231_hist.zip'       \n",
    "       }\n",
    "    \n",
    "    air_temp = getDwdData(urls['air_temp'], path,'air_temp.zip')\n",
    "\n",
    "    air_temp_extr = getDwdData(urls['air_temp_extr'], path,'air_temp_extr.zip')\n",
    "\n",
    "    wind = getDwdData(urls['wind'], path,'wind.zip')\n",
    "\n",
    "    wind_extr = getDwdData(urls['wind_extr'], path,'wind_extr.zip')\n",
    "\n",
    "    precipitation = getDwdData(urls['precipitation'], path,'precipitation.zip')\n",
    "\n",
    "    solar = getDwdData(urls['solar'], path,'solar.zip')\n",
    "    print('Cleaning air_temp')\n",
    "\n",
    "    air_temp = filterForYear(air_temp, 2019)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    air_temp.drop(columns={'STATIONS_ID','  QN', 'PP_10','eor'}, inplace=True)\n",
    "\n",
    "    # Assign interpretable column names\n",
    "    air_temp.rename(columns={\"TT_10\": \"temp_2m\", \"TM5_10\": \"temp_5cm\", \"RF_10\":\"humidity_2m\",\"TD_10\":\"dew_point_2m\"}, inplace=True)\n",
    "    air_temp.drop(columns={'temp_5cm'}, inplace=True)\n",
    "    \n",
    "    air_temp.replace(-999,float('NaN'), inplace=True)\n",
    "    air_temp.dropna(inplace=True)\n",
    "\n",
    "    print('Cleaning air_temp_extr')\n",
    "\n",
    "    air_temp_extr = filterForYear(air_temp_extr, 2019)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    air_temp_extr.drop(columns=['STATIONS_ID', '  QN','eor'], inplace=True)\n",
    "\n",
    "    # Assign interpretable column names\n",
    "    \n",
    "    air_temp_extr.rename(columns={'TX_10':'max_at_2m', 'TX5_10':'max_at_5cm','TN_10':'min_at_2m','TN5_10':'min_at_5cm'}, inplace=True)\n",
    "    air_temp_extr.drop(columns={'min_at_2m','min_at_5cm'}, inplace=True)\n",
    "    air_temp_extr.drop(columns={'max_at_5cm'}, inplace=True)\n",
    "    \n",
    "    air_temp_extr.replace(-999,float('NaN'), inplace=True)\n",
    "    air_temp_extr.dropna(inplace=True)\n",
    "    \n",
    "    print('Cleaning wind')\n",
    "\n",
    "    wind = filterForYear(wind, 2019)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    wind.drop(columns={'STATIONS_ID','  QN','eor'}, inplace=True)\n",
    "\n",
    "    # Assign interpretable column names\n",
    "    wind.rename(columns={'FF_10':'mean_speed_h/s','DD_10':'direction_degree'}, inplace=True)\n",
    "    \n",
    "    wind.replace(-999,float('NaN'), inplace=True)\n",
    "    wind.dropna(inplace=True)\n",
    "    \n",
    "    print('Cleaning wind_extr')\n",
    "\n",
    "    wind_extr = filterForYear(wind_extr, 2019)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    wind_extr.drop(columns={'STATIONS_ID','  QN','eor'}, inplace=True)\n",
    "\n",
    "    # Assign interpretable column names\n",
    "    wind_extr.rename(columns={'FX_10':'max_m/s','FNX_10':'min_mean_m/s','FMX_10':'max_mean_m/s','DX_10':'direction_degree'}, inplace=True)\n",
    "    \n",
    "    wind_extr.replace(-999,float('NaN'), inplace=True)\n",
    "    wind_extr.dropna(inplace=True)\n",
    "    \n",
    "    print('Cleaning precipitation')\n",
    "\n",
    "    precipitation = filterForYear(precipitation, 2019)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    precipitation.drop(columns={'STATIONS_ID','  QN','eor','RWS_IND_10'}, inplace=True)\n",
    "\n",
    "    # Assign interpretable column names\n",
    "    precipitation.rename(columns={'RWS_DAU_10':'min','RWS_10':'mm'}, inplace=True)\n",
    "   \n",
    "    precipitation.replace(-999,float('NaN'), inplace=True)\n",
    "    precipitation.dropna(inplace=True)\n",
    "    \n",
    "    print('Cleaning solar')\n",
    "\n",
    "    solar = filterForYear(solar, 2019)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    solar.drop(columns={'STATIONS_ID','  QN','eor'}, inplace=True)\n",
    "\n",
    "    # Assign interpretable column names\n",
    "    solar.rename(columns={'DS_10':'diffuse_radiation','GS_10':'incoming_radiation','SD_10':'duration_h','LS_10':'longwave_downward_radiation'}, inplace=True)\n",
    "    \n",
    "    solar.drop(columns={'longwave_downward_radiation'}, inplace=True)\n",
    "\n",
    "    solar.replace(-999,float('NaN'), inplace=True)\n",
    "    solar.dropna(inplace=True)\n",
    "    \n",
    "    print('Merging all weather data...')\n",
    "\n",
    "    all_weather = pd.merge(air_temp, air_temp_extr, on='timestamp')\n",
    "\n",
    "    all_weather = pd.merge(all_weather, wind, on='timestamp')\n",
    "\n",
    "    all_weather = pd.merge(all_weather, wind_extr, on='timestamp')\n",
    "\n",
    "    all_weather = pd.merge(all_weather, precipitation, on='timestamp')\n",
    "\n",
    "    print(all_weather.where(all_weather==-999).count())\n",
    "    \n",
    "    all_weather.to_csv(path + 'weather.gz', compression='gzip')\n",
    "\n",
    "    print('Getting and cleaning of weather data successful!')\n",
    "    print('Data saved as ' + path + 'weather.gz')\n",
    "    print('To import the data use the following command:')\n",
    "    print(\"pd.read_csv(path + 'weather.gz', index_col='timestamp')\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download air_temp.zip from https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/10_minutes/air_temperature/historical/10minutenwerte_TU_00691_20100101_20191231_hist.zip and save to ../data/external/\n",
      "\n",
      "Created data frame of air_temp.zip\n",
      "Zip file removed: ../data/external/air_temp.zip\n",
      "Download air_temp_extr.zip from https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/10_minutes/extreme_temperature/historical/10minutenwerte_extrema_temp_00691_20100101_20191231_hist.zip and save to ../data/external/\n",
      "\n",
      "Created data frame of air_temp_extr.zip\n",
      "Zip file removed: ../data/external/air_temp_extr.zip\n",
      "Download wind.zip from https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/10_minutes/wind/historical/10minutenwerte_wind_00691_20100101_20191231_hist.zip and save to ../data/external/\n",
      "\n",
      "Created data frame of wind.zip\n",
      "Zip file removed: ../data/external/wind.zip\n",
      "Download wind_extr.zip from https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/10_minutes/extreme_wind/historical/10minutenwerte_extrema_wind_00691_20100101_20191231_hist.zip and save to ../data/external/\n",
      "\n",
      "Created data frame of wind_extr.zip\n",
      "Zip file removed: ../data/external/wind_extr.zip\n",
      "Download precipitation.zip from https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/10_minutes/precipitation/historical/10minutenwerte_nieder_00691_20100101_20191231_hist.zip and save to ../data/external/\n",
      "\n",
      "Created data frame of precipitation.zip\n",
      "Zip file removed: ../data/external/precipitation.zip\n",
      "Download solar.zip from https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/10_minutes/solar/historical/10minutenwerte_SOLAR_00691_20100101_20191231_hist.zip and save to ../data/external/\n",
      "\n",
      "Created data frame of solar.zip\n",
      "Zip file removed: ../data/external/solar.zip\n",
      "Cleaning air_temp\n",
      "Cleaning air_temp_extr\n",
      "Cleaning wind\n",
      "Cleaning wind_extr\n",
      "Cleaning precipitation\n",
      "Cleaning solar\n",
      "Merging all weather data...\n",
      "Getting and cleaning of weather data successful!\n",
      "Data saved as ../data/external/weather.gz\n",
      "To import the data use the following command:\n",
      "pd.read_csv(path + 'weather.gz', index_col='timestamp')\n"
     ]
    }
   ],
   "source": [
    "prepWeather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = pd.read_csv(path + 'weather.gz', index_col='timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "temp_2m               0\n",
       "humidity_2m           0\n",
       "dew_point_2m          0\n",
       "max_at_2m             0\n",
       "mean_speed_h/s        0\n",
       "direction_degree_x    0\n",
       "max_m/s               0\n",
       "min_mean_m/s          0\n",
       "max_mean_m/s          0\n",
       "direction_degree_y    0\n",
       "min                   0\n",
       "mm                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTripsFrame():\n",
    "    data = pd.read_csv('../data/processed/trips_cleaned.csv',  index_col=0 )\n",
    "    data['start_time'] = pd.to_datetime(data['start_time'])\n",
    "    data['end_time'] = pd.to_datetime(data['end_time'])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def mergeWeatherTrips(trips, weather):\n",
    "    weather['timestamp'] = pd.to_datetime(weather['timestamp'])\n",
    "    \n",
    "    # Floor start time to next 10 minutes so we can merge it with weather data\n",
    "\n",
    "    trips['sTime_floored'] = pd.to_datetime(trips['start_time']).dt.floor('10T')\n",
    "    trips['sTime_floored'] = pd.to_datetime(trips['sTime_floored'])\n",
    "    data = trips.merge(right= weather, left_on='sTime_floored', right_on='timestamp', how='left')\n",
    "    data.drop(columns=['sTime_floored'], inplace=True)\n",
    "    print(\"Trip and weather data merged\")\n",
    "    print(\"Clean data\")\n",
    "    data.drop(columns=[\"bike_type\", \"mm\"], inplace=True)\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    data.to_csv('../data/processed/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip and weather data merged\n",
      "Clean data\n"
     ]
    }
   ],
   "source": [
    "trips = getTripsFrame()\n",
    "weather = pd.read_csv('../data/external/weather.gz', compression='gzip')\n",
    "mergeWeatherTrips(trips, weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
