{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import used packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from datetime import date, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "import folium\n",
    "from tqdm import tqdm\n",
    "sys.path.insert(0,\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bremen_trips = pd.read_csv(\"../data/processed/trips_weather.csv\", index_col=0)\n",
    "bremen_trips = bremen_trips.sort_values(by=['start_time'], ascending=True)\n",
    "bremen_trips[\"start_time\"] = pd.to_datetime(bremen_trips[\"start_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bremen_trips.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions that calculates distance moved towards the university of Bremen and main station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that calculates if start or end location is closer to University of Bremen. \n",
    "# Returns the difference of the distances of the start and end location in kilometers.\n",
    "# If value positive, end locations is closer to university. That means moved towards university.\n",
    "def distanceToUni(sLng,sLat,eLng,eLat):\n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0\n",
    "    \n",
    "    sLng = radians(sLng)\n",
    "    sLat = radians(sLat)\n",
    "    eLng = radians(eLng)\n",
    "    eLat = radians(eLat)\n",
    "    uLat = radians(53.1069302) # University of Bremen Latitude\n",
    "    uLng = radians(8.8499603)  # University of Bremen Longitude\n",
    "\n",
    "    sdlon = uLng - sLng\n",
    "    sdlat = uLat - sLat\n",
    "\n",
    "    edlon = uLng - eLng\n",
    "    edlat = uLat - eLat\n",
    "\n",
    "    sA = sin(sdlat / 2)**2 + cos(sLat) * cos(uLat) * sin(sdlon / 2)**2\n",
    "    eA = sin(edlat / 2)**2 + cos(eLat) * cos(uLat) * sin(edlon / 2)**2\n",
    "    \n",
    "    sC = 2 * atan2(sqrt(sA), sqrt(1 - sA))\n",
    "    eC = 2 * atan2(sqrt(eA), sqrt(1 - eA))\n",
    "\n",
    "    sDist = R * sC\n",
    "    eDist = R * eC\n",
    "\n",
    "    distance = sDist - eDist\n",
    "    \n",
    "    return distance\n",
    "\n",
    "def distanceToMainStation(sLng,sLat,eLng,eLat):\n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0\n",
    "    \n",
    "    sLng = radians(sLng)\n",
    "    sLat = radians(sLat)\n",
    "    eLng = radians(eLng)\n",
    "    eLat = radians(eLat)\n",
    "    msLat = radians(53.083122) # # Main station Latitude\n",
    "    msLng = radians(8.813717) # # Main station Latitude\n",
    "\n",
    "    sdlon = msLng - sLng\n",
    "    sdlat = msLat - sLat\n",
    "\n",
    "    edlon = msLng - eLng\n",
    "    edlat = msLat - eLat\n",
    "\n",
    "    sA = sin(sdlat / 2)**2 + cos(sLat) * cos(msLat) * sin(sdlon / 2)**2\n",
    "    eA = sin(edlat / 2)**2 + cos(eLat) * cos(msLat) * sin(edlon / 2)**2\n",
    "    \n",
    "    sC = 2 * atan2(sqrt(sA), sqrt(1 - sA))\n",
    "    eC = 2 * atan2(sqrt(eA), sqrt(1 - eA))\n",
    "\n",
    "    sDist = R * sC\n",
    "    eDist = R * eC\n",
    "\n",
    "    distance = sDist - eDist\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of trip moving away from the university\n",
    "\n",
    "- Red marker = University of Bremen\n",
    "- Blue marker = Start location\n",
    "- Green marker = End location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[53.1069302,8.8499603], zoom_start=13)\n",
    "\n",
    "folium.Marker([53.1069302,8.8499603], popup='<i>Uni</i>',icon=folium.Icon(color='red')).add_to(m)\n",
    "folium.Marker([53.083122,8.813717], popup='<i>Main Station</i>',icon=folium.Icon(color='red')).add_to(m)\n",
    "\n",
    "row = 35\n",
    "folium.Marker([bremen_trips.iloc[row,5],bremen_trips.iloc[row,4]], popup='<i>Start</i>').add_to(m)\n",
    "folium.Marker([bremen_trips.iloc[row,7],bremen_trips.iloc[row,6]], popup='<i>End</i>',icon=folium.Icon(color='green')).add_to(m)\n",
    "\n",
    "print('Moved km in direction to uni: ', distanceToUni(bremen_trips.iloc[row,4],bremen_trips.iloc[row,5],bremen_trips.iloc[row,6],bremen_trips.iloc[row,7]))\n",
    "print('Moved km in direction to main station: ', distanceToMainStation(bremen_trips.iloc[row,4],bremen_trips.iloc[row,5],bremen_trips.iloc[row,6],bremen_trips.iloc[row,7]))\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add to_uni, to_main_station and direction attribute to trips data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_uni = []\n",
    "to_main_station = []\n",
    "to_uni_bool = []\n",
    "to_main_station_bool = []\n",
    "month = []\n",
    "week_day = []\n",
    "is_weekend = []\n",
    "hour = []\n",
    "\n",
    "\n",
    "for index, row in tqdm(bremen_trips.iterrows()):\n",
    "    \n",
    "    dist_to_uni = distanceToUni(row['start_lng'],row['start_lat'],row['end_lng'],row['end_lat'])\n",
    "    dist_to_main_station = distanceToMainStation(row['start_lng'],row['start_lat'],row['end_lng'],row['end_lat'])\n",
    "    \n",
    "    day = row['start_time'].weekday()\n",
    "    \n",
    "    # Save datetime information\n",
    "    month.append(row['start_time'].month)\n",
    "    week_day.append(day)\n",
    "    hour.append(row['start_time'].hour)\n",
    "    \n",
    "    if (day == 5) | (day == 6):\n",
    "        is_weekend.append(1)\n",
    "    else:\n",
    "        is_weekend.append(0)\n",
    "    \n",
    "    # Save distances to corresponding list\n",
    "    to_uni.append(dist_to_uni)\n",
    "    to_main_station.append(dist_to_main_station)\n",
    "    \n",
    "    if dist_to_uni < 0:\n",
    "        to_uni_bool.append(0)\n",
    "    else:\n",
    "        to_uni_bool.append(1)\n",
    "        \n",
    "    if dist_to_main_station < 0:\n",
    "        to_main_station_bool.append(0)\n",
    "    else:\n",
    "        to_main_station_bool.append(1)\n",
    "        \n",
    "\n",
    "bremen_trips['to_uni'] = to_uni\n",
    "bremen_trips['to_main_station'] = to_main_station\n",
    "bremen_trips['to_uni_bool'] = to_uni_bool\n",
    "bremen_trips['to_main_station_bool'] = to_main_station_bool\n",
    "bremen_trips['month'] = month\n",
    "bremen_trips['week_day'] = week_day\n",
    "bremen_trips['is_weekend'] = is_weekend\n",
    "bremen_trips['hour'] = hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bremen_trips.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on correlations to_uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bremen_trips.drop(columns={'end_lng','end_lat','end_place','to_uni','to_uni_bool','to_main_station_bool','to_main_station','duration_sec','identification'}).corrwith(bremen_trips['to_uni'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson correlation only for attributes with correlation higher than 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Using Pearson Correlation\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "cor = bremen_trips[['to_uni','start_lng','start_lat','start_place']].corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on correlations to_main_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bremen_trips.drop(columns={'end_lng','end_lat','end_place','to_uni_bool','to_main_station_bool','to_uni','to_main_station','duration_sec','identification'}).corrwith(bremen_trips['to_main_station'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson correlation only for attributes with correlation higher than 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Using Pearson Correlation\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "cor = bremen_trips[['to_main_station','start_lng','start_place','humidity_2m']].corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on correlations to_main_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bremen_trips.drop(columns={'end_lng','end_lat','end_place','to_uni','to_uni_bool','to_main_station_bool','to_main_station','duration_sec','identification'}).corrwith(bremen_trips['to_uni_bool'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson correlation only for attributes with correlation higher than 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Pearson Correlation\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "cor = bremen_trips[['to_uni_bool','start_lng','start_place','humidity_2m','month']].corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting to_uni_bool - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize independent and target variable\n",
    "X = bremen_trips[['start_lng','start_lat','start_place','humidity_2m','month']]\n",
    "y = bremen_trips['to_uni_bool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and validation set\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.60, shuffle=True, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.60, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(criterion='entropy', class_weight='balanced_subsample')\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training accuracy: ' + str(rf.score(X_train, y_train)))\n",
    "print('Valiation accuracy: ' + str(rf.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that plots a confusion matrix given independent and target variable\n",
    "def confusionMatrix(y, X):\n",
    "    cm = confusion_matrix(y_val, rf.predict(X_val))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(cm)\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "    ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "    ax.set_ylim(1.5, -0.5)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMatrix(y_val, rf.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_val, rf.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing grid search to optimize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth':[2, 3, 4, 5, 7],\n",
    "              'n_estimators':[1, 10, 25, 50, 100, 256, 512],\n",
    "              'random_state':[42]}\n",
    "    \n",
    "def perform_grid_search(X_data, y_data):\n",
    "    rf = RandomForestClassifier(criterion='entropy', class_weight='balanced_subsample')\n",
    "    \n",
    "    clf = GridSearchCV(rf, parameters, cv=4, scoring='accuracy', n_jobs=3)\n",
    "    \n",
    "    clf.fit(X_data, y_data)\n",
    "    \n",
    "    print(clf.cv_results_['mean_test_score'])\n",
    "    \n",
    "    return clf.best_params_['n_estimators'], clf.best_params_['max_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract parameters\n",
    "n_estimator, depth = perform_grid_search(X_val, y_val)\n",
    "c_random_state = 42\n",
    "print(n_estimator, depth, c_random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(criterion='entropy', class_weight='balanced_subsample', n_estimators=n_estimator, max_depth=depth)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training accuracy: ' + str(rf.score(X_train, y_train)))\n",
    "print('Valiation accuracy: ' + str(rf.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMatrix(y_val, rf.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_val, rf.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add validation set to train set to obtain more training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.append(X_val)\n",
    "y_train = y_train.append(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(criterion='entropy', class_weight='balanced_subsample', n_estimators=n_estimator, max_depth=depth)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training + validation set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training accuracy: ' + str(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set performance\n",
    "\n",
    "### The moment of truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test accuracy: ' + str(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize independent and target variable\n",
    "X = bremen_trips[['start_lng','start_lat','start_plz','month']]\n",
    "y = bremen_trips['to_uni_bool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and validation set\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.60, shuffle=True)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.60, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear',multi_class='ovr', random_state=42, class_weight='balanced').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training accuracy: ' + str(model.score(X_train, y_train)))\n",
    "print('Valiation accuracy: ' + str(model.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMatrix(y_val, model.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_val, model.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression performs worst than random forest. Do not use it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting to_main_station_bool - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize independent and target variable\n",
    "X = bremen_trips[['start_lng','start_lat','start_plz','month']]\n",
    "y = bremen_trips['to_main_station_bool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and validation set\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.60, shuffle=True)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.60, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(criterion='entropy', class_weight='balanced_subsample')\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training accuracy: ' + str(rf.score(X_train, y_train)))\n",
    "print('Valiation accuracy: ' + str(rf.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMatrix(y_val, rf.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_val, rf.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing grid search to optimize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth':[2, 3, 4, 5, 7],\n",
    "              'n_estimators':[1, 10, 25, 50, 100, 256, 512],\n",
    "              'random_state':[42]}\n",
    "    \n",
    "def perform_grid_search(X_data, y_data):\n",
    "    rf = RandomForestClassifier(criterion='entropy', class_weight='balanced_subsample')\n",
    "    \n",
    "    clf = GridSearchCV(rf, parameters, cv=4, scoring='accuracy', n_jobs=3)\n",
    "    \n",
    "    clf.fit(X_data, y_data)\n",
    "    \n",
    "    print(clf.cv_results_['mean_test_score'])\n",
    "    \n",
    "    return clf.best_params_['n_estimators'], clf.best_params_['max_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract parameters\n",
    "n_estimator, depth = perform_grid_search(X_val, y_val)\n",
    "c_random_state = 42\n",
    "print(n_estimator, depth, c_random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(criterion='entropy', class_weight='balanced_subsample', n_estimators=n_estimator, max_depth=depth)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training accuracy: ' + str(rf.score(X_train, y_train)))\n",
    "print('Valiation accuracy: ' + str(rf.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMatrix(y_val, rf.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_val, rf.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add validation set to train set to obtain more training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.append(X_val)\n",
    "y_train = y_train.append(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(criterion='entropy', class_weight='balanced_subsample', n_estimators=n_estimator, max_depth=depth)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training + validation set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training accuracy: ' + str(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set performance\n",
    "\n",
    "### The moment of truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test accuracy: ' + str(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting to_uni - Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize independent and target variable\n",
    "X = bremen_trips[['start_lng','start_lat','start_place']]\n",
    "y = bremen_trips['to_uni']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and validation set\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.60, shuffle=True, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.60, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseDegree(X, y):\n",
    "    \n",
    "    # Splitting data into train and validation set\n",
    "    #X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.60, shuffle=True)\n",
    "    #X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.60, shuffle=True)\n",
    "\n",
    "    r2_train = []\n",
    "    r2_val = []\n",
    "    rmses_val = []\n",
    "    degrees = np.arange(1, 8)\n",
    "    min_rmse, min_deg = 1e10, 0\n",
    "\n",
    "    for deg in degrees:\n",
    "\n",
    "        # Train features\n",
    "        poly_features = PolynomialFeatures(degree=deg, include_bias=False)\n",
    "        X_poly_train = poly_features.fit_transform(X_train)\n",
    "\n",
    "        # Linear regression\n",
    "        poly_reg = LinearRegression()\n",
    "        poly_reg.fit(X_poly_train, y_train)\n",
    "        X_val_poly = poly_features.fit_transform(X_val)\n",
    "        \n",
    "        # Evaluate\n",
    "        r2_train.append(poly_reg.score(X_poly_train, y_train))\n",
    "        r2_val.append(poly_reg.score(X_val_poly,y_val))\n",
    "\n",
    "        # Compare with val data\n",
    "        poly_predict = poly_reg.predict(X_val_poly)\n",
    "        poly_mse = mean_squared_error(y_val, poly_predict)\n",
    "        poly_rmse = np.sqrt(poly_mse)\n",
    "        rmses_val.append(poly_rmse)\n",
    "\n",
    "        # Cross-validation of degree\n",
    "        if min_rmse > poly_rmse:\n",
    "            min_rmse = poly_rmse\n",
    "            min_deg = deg\n",
    "\n",
    "    # Plot and present results\n",
    "    print('Suggested degree {} with RMSE of validation set {}'.format(min_deg, min_rmse))\n",
    "    \n",
    "    # Create model with optimal degree\n",
    "    poly_features = PolynomialFeatures(degree=min_deg, include_bias=False)\n",
    "    X_poly_train = poly_features.fit_transform(X_train)\n",
    "\n",
    "    # Linear regression\n",
    "    poly_reg = LinearRegression()\n",
    "    poly_reg.fit(X_poly_train, y_train)\n",
    "    X_val_poly = poly_features.fit_transform(X_val)\n",
    "\n",
    "    # Evaluate\n",
    "    print('R2 train score with suggested degree: ', poly_reg.score(X_poly_train, y_train))\n",
    "    print('R2 validation score with suggested degree: ', poly_reg.score(X_val_poly,y_val))\n",
    "    \n",
    "    \n",
    "    # Evaluation plots\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 8))\n",
    "    \n",
    "    #ax_rmses_val = fig.add_subplot(111)\n",
    "    axes[0].plot(degrees, rmses_val, label='rmses_val')\n",
    "    axes[0].set_yscale('log')\n",
    "    axes[0].set_xlabel('Degree')\n",
    "    axes[0].set_ylabel('RMSE')\n",
    "    \n",
    "    #ax_r2_train = fig.add_subplot(111)\n",
    "    axes[1].plot(degrees, r2_train, label='R2_train')\n",
    "    axes[1].set_yscale('linear')\n",
    "    axes[1].set_xlabel('Degree')\n",
    "    axes[1].set_ylabel('R2_train')\n",
    "    axes[1].set_label('R2_train')\n",
    "    #axes[1].set_ylim(0,1)\n",
    "    \n",
    "    #ax_r2_val = fig.add_subplot(111)\n",
    "    axes[1].plot(degrees, r2_val, label='R2_val')\n",
    "    axes[1].set_xlabel('Degree')\n",
    "    axes[1].set_ylabel('R2_val')\n",
    "    \n",
    "    axes[0].legend()\n",
    "    axes[1].legend()\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chooseDegree(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add validation set to train set to obtain more training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.append(X_val)\n",
    "y_train = y_train.append(y_val)\n",
    "\n",
    "poly = PolynomialFeatures(3)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "\n",
    "lin = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training + validation set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin.fit(X_train_poly, y_train)\n",
    "lin.score(X_train_poly, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_poly = poly.fit_transform(X_test)\n",
    "lin.score(X_test_poly,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting to_main_station - Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize independent and target variable\n",
    "X = bremen_trips.dropna()[['start_lng','start_place','start_place','humidity_2m']]\n",
    "y = bremen_trips.dropna()['to_main_station']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and validation set\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.60, shuffle=True, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.60, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chooseDegree(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add validation set to train set to obtain more training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.append(X_val)\n",
    "y_train = y_train.append(y_val)\n",
    "\n",
    "poly = PolynomialFeatures(9)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "\n",
    "lin = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training + validation set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin.fit(X_train_poly, y_train)\n",
    "lin.score(X_train_poly, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_poly = poly.fit_transform(X_test)\n",
    "lin.score(X_test_poly,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (PDS_Project)",
   "language": "python",
   "name": "pycharm-c25bd02c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
